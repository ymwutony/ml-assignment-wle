---
output: html_document
---
# Overview
The main goal of the project is to predict the manner in which 6 participants performed some exercise which represents by the variable "classe" in the data set. The machine learning algorithm described here will be used for predict 20 test cases in the test data.

Load required packages
```
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
```

Set seed
```
set.seed(414)
```

Load data
```
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
```
Divide Training data to "Training" and "Validation". The "Validation" set will be used for estimating out of sample error.
```
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; 
myValidation <- training[-inTrain, ]
```
Tidy up the training data by removing zero-variance predictors and non-predictive variables like ID, user_name and timestamp for the records.
```
myNearZero <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[!myNearZero$nzv]
myTraining <- myTraining[, -(1:6)]
```

Remove Column that have more than 60% missing value
```
rmCol <- sapply(colnames(myTraining), function(x) if(sum(is.na(myTraining[, x])) > 0.50*nrow(myTraining)) { return(TRUE)
}else{
        return(FALSE)
}
)
myTraining <- myTraining[, !rmCol]
```

Tidy up the validation and test data
```
clean1 <- colnames(myTraining)
clean2 <- clean1[-53]
myValidation <- myValidation[clean1]
testing <- testing[clean2]
```

Use Random Forests for prediction
```
modFit <- randomForest(classe ~. , data=myTraining)
predictionRF <- predict(modFit, myValidation, type = "class")
```

Use confusion Matrix to test results
```
caret::confusionMatrix(predictionRF, myValidation$classe)
```

## Result
### Confusion Matrix and Statistics
```
                Reference
Prediction    A    B    C    D    E
         A 2231    0    0    0    0
         B    1 1518    3    0    0
         C    0    0 1364    7    0
         D    0    0    1 1278    1
         E    0    0    0    1 1441

Overall Statistics
                                        
               Accuracy : 0.9982        
                 95% CI : (0.997, 0.999)
    No Information Rate : 0.2845        
    P-Value [Acc > NIR] : < 2.2e-16     
                                        
                  Kappa : 0.9977        
 Mcnemar's Test P-Value : NA            

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9996   1.0000   0.9971   0.9938   0.9993
Specificity            1.0000   0.9994   0.9989   0.9997   0.9998
Pos Pred Value         1.0000   0.9974   0.9949   0.9984   0.9993
Neg Pred Value         0.9998   1.0000   0.9994   0.9988   0.9998
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2843   0.1935   0.1738   0.1629   0.1837
Detection Prevalence   0.2843   0.1940   0.1747   0.1631   0.1838
Balanced Accuracy      0.9998   0.9997   0.9980   0.9967   0.9996
```

Apply the selected model to the test data
```
predictResult <- predict(predictionRF, newdata=testing)
predictResult
```
